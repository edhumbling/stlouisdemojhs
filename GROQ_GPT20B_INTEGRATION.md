# Groq GPT-20B Integration Documentation

## üìã Overview

This document provides comprehensive documentation for the Louis AI chatbot integration with Groq's GPT-20B model. The system uses Groq's ultra-fast inference infrastructure to provide enhanced language understanding and generation capabilities.

## üèóÔ∏è Architecture

### **Service Stack**
```
Louis AI Chatbot
    ‚Üì
Unified AI Service
    ‚Üì
OpenRouter Service (Groq Integration)
    ‚Üì
Groq Platform (GPT-20B)
```

### **Key Components**
- **Frontend**: React-based Louis AI interface
- **AI Service**: `src/services/openRouterService.ts` (Groq integration)
- **Unified Service**: `src/services/unifiedAIService.ts` (facade pattern)
- **Environment**: Vite + TypeScript + Tailwind CSS

## üîß Configuration

### **API Configuration**
```typescript
// src/services/openRouterService.ts
class OpenRouterService {
  private apiKey: string;
  private apiEndpoint: string;
  private model: string;

  constructor() {
    this.apiKey = import.meta.env.VITE_GROQ_API_KEY || 'your_groq_api_key_here';
    this.apiEndpoint = 'https://api.groq.com/openai/v1/chat/completions';
    this.model = 'openai/gpt-oss-20b';
  }
}
```

### **Environment Variables**
```bash
# .env file
VITE_GROQ_API_KEY=your_groq_api_key_here
```

### **Vercel Environment Variables**
- **Variable**: `VITE_GROQ_API_KEY`
- **Value**: Your actual Groq API key
- **Scope**: Production, Preview, Development

## üöÄ API Integration Details

### **Request Format with Fallback**
```typescript
// Primary model attempt
const requestBody = {
  model: 'openai/gpt-oss-20b', // Primary model
  messages: [
    {
      role: 'system',
      content: systemPrompt
    },
    {
      role: 'user',
      content: userMessage
    }
  ],
  temperature: 0.7,
  max_tokens: 2048,
  top_p: 0.9,
  frequency_penalty: 0.1,
  presence_penalty: 0.1,
  user: 'stlouisdemojhs-user'
};

// Automatic fallback to GPT-120B if primary fails
// Fallback model: 'openai/gpt-oss-120b'
```

### **Headers**
```typescript
const headers = {
  'Authorization': `Bearer ${this.apiKey}`,
  'Content-Type': 'application/json'
};
```

### **Response Handling**
```typescript
const data: OpenRouterResponse = await response.json();
const choice = data.choices[0];
const content = choice.message.content;
```

## üìä Model Specifications

### **Model Configuration**
- **Primary Model**: `openai/gpt-oss-20b` (20 billion parameters)
- **Fallback Model**: `openai/gpt-oss-120b` (120 billion parameters)
- **Speech Model**: `whisper-large-v3` (speech-to-text)
- **Provider**: OpenAI (via Groq)
- **Capabilities**: Advanced language understanding, generation, reasoning, speech recognition
- **Speed**: Ultra-fast inference via Groq's optimized infrastructure
- **Reliability**: Automatic fallback ensures high availability

### **Performance Characteristics**
- **Latency**: Sub-second response times
- **Throughput**: High concurrent request handling
- **Reliability**: 99.9% uptime via Groq platform
- **Cost**: Competitive pricing with high performance

## üõ†Ô∏è Development Setup

### **Prerequisites**
- Node.js 18+ 
- npm/yarn package manager
- Groq API key
- Vite development environment

### **Installation Steps**
1. **Clone Repository**
   ```bash
   git clone <repository-url>
   cd stlouisdemojhs
   ```

2. **Install Dependencies**
   ```bash
   npm install
   ```

3. **Environment Setup**
   ```bash
   # Create .env file
   echo "VITE_GROQ_API_KEY=your_groq_api_key_here" > .env
   ```

4. **Development Server**
   ```bash
   npm run dev
   ```

### **Production Deployment**
1. **Build Application**
   ```bash
   npm run build
   ```

2. **Deploy to Vercel**
   - Connect repository to Vercel
   - Set environment variable `VITE_GROQ_API_KEY`
   - Deploy automatically on push to main

## üîç Error Handling

### **Fallback Error Handling**
```typescript
// Primary model attempt
try {
  return await this.makeApiRequest(userMessage, context, conversationHistory, sources, this.primaryModel);
} catch (error) {
  console.warn('‚ö†Ô∏è Primary model (GPT-20B) failed, trying fallback (GPT-120B):', error);
  
  // Automatic fallback to GPT-120B
  try {
    return await this.makeApiRequest(userMessage, context, conversationHistory, sources, this.fallbackModel);
  } catch (fallbackError) {
    console.error('‚ùå Both primary and fallback models failed');
    throw fallbackError;
  }
}

// Common error scenarios
if (error instanceof TypeError && error.message.includes('Failed to fetch')) {
  throw new Error('NETWORK_ERROR');
}

// API errors
if (response.status === 429) {
  throw new Error('HIGH_TRAFFIC');
} else if (response.status === 401) {
  throw new Error('API_KEY_INVALID');
} else if (response.status >= 500) {
  throw new Error('SERVICE_UNAVAILABLE');
}
```

### **User-Friendly Messages**
- **High Traffic**: "We are currently experiencing high traffic. Please come back later."
- **Technical Issues**: "We are currently experiencing technical difficulties. Please try again later."
- **Network Issues**: Automatic retry with fallback mechanisms

## üìà Monitoring & Analytics

### **Usage Tracking**
```typescript
// Log usage statistics
if (data.usage) {
  console.log('üìä Groq Usage:', {
    prompt_tokens: data.usage.prompt_tokens,
    completion_tokens: data.usage.completion_tokens,
    total_tokens: data.usage.total_tokens,
    model: data.model
  });
}
```

### **Performance Metrics**
- **Response Time**: Track API call duration
- **Token Usage**: Monitor token consumption
- **Error Rates**: Track failure rates and types
- **User Engagement**: Monitor chatbot interactions

## üîí Security Considerations

### **API Key Management**
- **Environment Variables**: Never hardcode API keys
- **Vercel Secrets**: Use Vercel's environment variable system
- **GitHub Protection**: Avoid committing sensitive keys
- **Rotation**: Regular API key rotation for security

### **Data Privacy**
- **No Data Storage**: Conversations not stored permanently
- **Secure Transmission**: HTTPS for all API calls
- **User Anonymization**: No personal data collection

## üé§ Speech-to-Text Integration

### **Whisper Large V3 Model**
- **Model**: `whisper-large-v3`
- **Provider**: Groq (same API key as AI service)
- **Capabilities**: Advanced speech recognition and transcription
- **Languages**: Multi-language support with high accuracy
- **Integration**: Seamless voice input for Louis AI chatbot

### **Speech Features**
- **Voice Input**: Users can speak instead of typing
- **Real-time Transcription**: Live speech-to-text conversion
- **Multi-language**: Support for multiple languages
- **High Accuracy**: Advanced Whisper model for precise transcription
- **Accessibility**: Enhanced user experience for all users

### **Implementation**
- **Browser Support**: Fallback to browser speech recognition
- **API Integration**: Whisper via Groq for advanced features
- **Error Handling**: Graceful fallback between speech methods
- **User Interface**: Microphone button with visual feedback

## üîÑ Fallback System

### **Automatic Model Switching**
- **Primary Model**: GPT-20B (fast, efficient)
- **Fallback Model**: GPT-120B (larger, more capable)
- **Seamless Transition**: Automatic switching on primary model failure
- **Zero Downtime**: Users experience no interruption during fallback

### **Fallback Triggers**
- **Model Unavailable**: Primary model temporarily unavailable
- **Rate Limiting**: High traffic on primary model
- **Service Errors**: 5xx errors from primary model
- **Network Issues**: Connectivity problems with primary model

### **Fallback Benefits**
- **High Availability**: 99.9%+ uptime through dual-model system
- **Performance**: Fast primary model with powerful fallback
- **Reliability**: Automatic failover ensures continuous service
- **Cost Optimization**: Use efficient primary model when possible

## üöÄ Performance Optimization

### **Caching Strategy**
- **Service Worker**: PWA caching for static assets
- **API Responses**: Intelligent caching for repeated queries
- **CDN**: Global content delivery via Vercel

### **Load Balancing**
- **Groq Infrastructure**: Automatic load balancing
- **Rate Limiting**: Built-in rate limiting protection
- **Fallback Mechanisms**: Graceful degradation on errors

## üìö API Reference

### **Groq API Endpoints**
- **Base URL**: `https://api.groq.com/openai/v1`
- **Chat Completions**: `/chat/completions`
- **Authentication**: Bearer token in Authorization header

### **Request Parameters**
| Parameter | Type | Description | Default |
|-----------|------|-------------|---------|
| `model` | string | Model identifier | `openai/gpt-oss-20b` (primary), `openai/gpt-oss-120b` (fallback) |
| `messages` | array | Conversation history | Required |
| `temperature` | number | Response randomness | 0.7 |
| `max_tokens` | number | Maximum response length | 2048 |
| `top_p` | number | Nucleus sampling | 0.9 |

### **Response Format**
```typescript
interface GroqResponse {
  id: string;
  object: string;
  created: number;
  model: string;
  choices: Array<{
    index: number;
    message: {
      role: string;
      content: string;
    };
    finish_reason: string;
  }>;
  usage: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
}
```

## üîÑ Maintenance & Updates

### **Regular Maintenance**
- **API Key Rotation**: Monthly key updates
- **Dependency Updates**: Regular package updates
- **Performance Monitoring**: Continuous performance tracking
- **Error Logging**: Comprehensive error tracking

### **Update Procedures**
1. **Test Changes**: Local testing with development environment
2. **Staging Deployment**: Test on staging environment
3. **Production Deployment**: Deploy to production with monitoring
4. **Rollback Plan**: Quick rollback procedures if issues arise

## üìû Support & Troubleshooting

### **Common Issues**
1. **"High Traffic" Error**
   - Check API key validity
   - Verify environment variable configuration
   - Check Groq service status

2. **Network Errors**
   - Verify internet connectivity
   - Check CORS configuration
   - Validate API endpoint accessibility

3. **Authentication Errors**
   - Verify API key format
   - Check environment variable naming
   - Ensure key has proper permissions

### **Debugging Tools**
- **Browser Console**: Check for JavaScript errors
- **Network Tab**: Monitor API requests/responses
- **Vercel Logs**: Check deployment logs
- **Groq Dashboard**: Monitor API usage and limits

## üìù Changelog

### **Version 1.1.0** (Current)
- ‚úÖ Initial Groq GPT-20B integration
- ‚úÖ GPT-120B fallback model integration
- ‚úÖ Automatic model switching
- ‚úÖ Enhanced error handling and user feedback
- ‚úÖ Performance optimization
- ‚úÖ Security best practices
- ‚úÖ High availability through dual-model system

### **Future Enhancements**
- üîÑ Advanced caching strategies
- üîÑ Real-time streaming responses
- üîÑ Enhanced analytics dashboard
- üîÑ Model performance monitoring

## üìû Contact & Support

### **Technical Support**
- **Documentation**: This file and inline code comments
- **Issues**: GitHub issues for bug reports
- **Updates**: Regular documentation updates

### **Resources**
- **Groq Documentation**: https://console.groq.com/docs
- **OpenAI API Reference**: https://platform.openai.com/docs
- **Vercel Documentation**: https://vercel.com/docs

---

**Last Updated**: January 2025  
**Version**: 1.0.0  
**Maintainer**: Development Team
